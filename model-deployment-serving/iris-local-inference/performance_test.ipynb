{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d294dd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c30ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uvicorn\n",
    "import requests\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373639b1",
   "metadata": {},
   "source": [
    "Ensure that the backend server is running before proceeding.\n",
    "\n",
    "If not, run this command within the directory.\n",
    "\n",
    "```\n",
    "uvicorn main:app --reload\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434f0c2",
   "metadata": {},
   "source": [
    "# Joblib Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b410982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joblib mean inference time: 0.0019896438121795655\n",
      "Joblib 95th percentile inference time: 0.002776598930358886\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:8000/predict_joblib\"\n",
    "payload = {\"features\": [5.1, 3.5, 1.4, 0.2]}\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "joblib_times = []\n",
    "\n",
    "for _ in range(1000):\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    end_time = time.time()\n",
    "    joblib_times.append(end_time - start_time)\n",
    "\n",
    "joblib_times = np.array(joblib_times)\n",
    "joblib_mean = joblib_times.mean()\n",
    "joblib_95th_percentile = np.percentile(joblib_times, 95)\n",
    "\n",
    "print(\"Joblib mean inference time:\", joblib_mean)\n",
    "print(\"Joblib 95th percentile inference time:\", joblib_95th_percentile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cabd6c",
   "metadata": {},
   "source": [
    "# ONNX Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a002297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX mean inference time: 0.002039801597595215\n",
      "ONNX 95th percentile inference time: 0.0037623763084411606\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:8000/predict_onnx\"\n",
    "payload = {\"features\": [5.1, 3.5, 1.4, 0.2]}\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "onnx_times = []\n",
    "\n",
    "for _ in range(1000):\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    end_time = time.time()\n",
    "    onnx_times.append(end_time - start_time)\n",
    "\n",
    "onnx_times = np.array(onnx_times)\n",
    "onnx_mean = onnx_times.mean()\n",
    "onnx_95th_percentile = np.percentile(onnx_times, 95)\n",
    "\n",
    "print(\"ONNX mean inference time:\", onnx_mean)\n",
    "print(\"ONNX 95th percentile inference time:\", onnx_95th_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f6fe76",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The performance comparison between joblib and ONNX backends shows minimal differences, with joblib achieving slightly better average latency (1.99ms vs 2.04ms) and consistency (P95 of 2.78ms vs 3.76ms). For this lightweight logistic regression model, both serialization formats deliver sub-4ms response times for 95% of requests, making the choice between them negligible from a performance standpoint. The decision should be based on deployment requirements: joblib for Python-native environments and ONNX for cross-platform compatibility, rather than performance considerations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
